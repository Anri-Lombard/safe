{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import safe as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/manu/.cache/huggingface/datasets/alxfgh___csv/alxfgh--ChEMBL_Drug_Instruction_Tuning-6e653d1656fb1fb2/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d774f6dc30f94baeb9a67b0b6f955e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset(\"alxfgh/ChEMBL_Drug_Instruction_Tuning\", streaming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = data[\"train\"]\n",
    "data = data.unique(\"SMILES\")\n",
    "df = pd.DataFrame({\"smiles\":data})\n",
    "data = datasets.Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datamol as dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "ALLOWED_DESCRIPTORS = [\"mw\", \"fsp3\", \"n_lipinski_hba\", \"n_lipinski_hbd\", \"n_rings\", \"n_heavy_atoms\", \"n_hetero_atoms\", \"n_rotatable_bonds\", \"tpsa\"]\n",
    "def apply_converter(row):\n",
    "    row[\"inputs\"] = sf.utils.convert_to_safe(row[\"smiles\"], canonical=False, randomize=True, fraction_hs=0.4)\n",
    "    descriptors_dict = dm.descriptors.compute_many_descriptors(dm.to_mol(row[\"smiles\"]))\n",
    "    row[\"descriptors\"] = [descriptors_dict[x] for x in ALLOWED_DESCRIPTORS]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c02f919f8c64517badc7214ee53da4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3892 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:44:31] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:44:31] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:44:31] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:44:31] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:44:31] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:44:31] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:44:31] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:44:31] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "processed_data = data.map(apply_converter, batched=False, remove_columns=[\"smiles\"], num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c655f21407430480301119aba94f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3892 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_data = processed_data.filter(lambda x: x[\"inputs\"] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf tmp_data/processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "processed_data = processed_data.train_test_split(\n",
    "    test_size=0.2,  seed=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data[\"validation\"] = processed_data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e739068244ee42b38c03b79bc444d68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1e970bf86c47eca8b108c32d175915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/751 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5f58ae8e3246e5b4948ad9afec2096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/751 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_data.save_to_disk(\"tmp_data/processed_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn an initial tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safe.tokenizer import SAFETokenizer\n",
    "from safe.trainer.data_utils import batch_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c004cb59194f599e7e9c7de3be148b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacbba4e9e71467aad39dfc95e404f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SAFETokenizer(trainer_args=dict(vocab_size=500), splitter=\"safe\")\n",
    "tokenizer.train_from_iterator(batch_iterator(processed_data, column=\"inputs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"tmp_data/tokenizer-splitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['inputs', 'descriptors'],\n",
       "        num_rows: 3001\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['inputs', 'descriptors'],\n",
       "        num_rows: 751\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['inputs', 'descriptors'],\n",
       "        num_rows: 751\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_tokenizer = tokenizer.get_pretrained()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize a version of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safe.trainer.data_utils import get_dataset, save_to_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d80c8ed0f442a49856502b100a7853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caae154280ef433f9e805fd047328315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/751 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09e660c2f124887ab8f592b6e02a3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/751 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = get_dataset(\"tmp_data/processed_data\", tokenizer=tokenizer, streaming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['inputs', 'descriptors', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3001\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['inputs', 'descriptors', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 751\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['inputs', 'descriptors', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 751\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the appropriate data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safe.trainer.collator import SafeCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = SafeCollator(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(tokenized_dataset[\"train\"], collate_fn=data_collator, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(processed_data[\"train\"], collate_fn=data_collator, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1, 34, 83, 63, 11, 34, 21, 78, 11, 34, 80, 27, 11, 34, 20, 22, 11, 27,\n",
       "         63, 27, 58, 11, 34, 60, 27, 11, 27, 68, 27, 19, 11, 27, 62, 27, 80, 11,\n",
       "         27, 22, 27, 84, 11, 27, 74, 27, 83, 11, 34, 19, 62, 11, 27, 21, 27, 20,\n",
       "         11, 34, 58, 68, 11, 34, 84, 74, 11, 57, 14, 78, 27, 27, 27, 15,  7, 34,\n",
       "          8, 57, 16, 27, 42, 17, 42, 42, 42, 60, 42, 18, 42, 17, 71, 15,  7, 27,\n",
       "         27, 33, 16, 27,  8, 57, 14, 34, 18,  2],\n",
       "        [ 1, 42, 14, 18, 42, 66, 42, 15, 42, 42, 42, 42, 16, 42, 14, 15, 11, 34,\n",
       "         16, 35,  7, 23, 34,  8,  7, 34,  8, 34, 11, 27, 17, 27, 18, 11, 33, 17,\n",
       "          7, 27,  8, 27,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3],\n",
       "        [ 1, 33, 14, 18, 27, 27, 33, 20, 27, 27, 14, 11, 42, 14, 21, 42, 42, 42,\n",
       "         15, 42,  7, 42, 14,  8, 34, 27,  7, 28,  8,  7, 28,  8, 34, 15, 11, 27,\n",
       "         19, 18, 23, 34, 11, 42, 14, 22, 42, 47, 42, 42, 42, 14, 61, 11, 27, 20,\n",
       "         21, 11, 33, 19, 22,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3],\n",
       "        [ 1, 42, 14, 42, 42, 42, 42,  7, 27, 23, 20, 61,  8, 42, 14, 11, 27,  7,\n",
       "         34,  8,  7, 27, 27,  7, 23, 34,  8, 34,  8,  7, 27, 27,  7, 23, 34,  8,\n",
       "         34,  8, 27,  7, 23, 34,  8, 34, 11, 33, 18, 21, 19, 11, 27, 21, 27, 11,\n",
       "         27, 17, 27, 18, 11, 34, 17, 16, 11, 27, 19, 27, 11, 27, 23, 20,  7, 42,\n",
       "         14, 42, 42, 42, 42, 42, 14,  8, 42, 14, 42, 42, 42, 16, 42, 42, 14,  2,\n",
       "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]]), 'labels': tensor([[   1,   34,   83,   63,   11,   34,   21,   78,   11,   34,   80,   27,\n",
       "           11,   34,   20,   22,   11,   27,   63,   27,   58,   11,   34,   60,\n",
       "           27,   11,   27,   68,   27,   19,   11,   27,   62,   27,   80,   11,\n",
       "           27,   22,   27,   84,   11,   27,   74,   27,   83,   11,   34,   19,\n",
       "           62,   11,   27,   21,   27,   20,   11,   34,   58,   68,   11,   34,\n",
       "           84,   74,   11,   57,   14,   78,   27,   27,   27,   15,    7,   34,\n",
       "            8,   57,   16,   27,   42,   17,   42,   42,   42,   60,   42,   18,\n",
       "           42,   17,   71,   15,    7,   27,   27,   33,   16,   27,    8,   57,\n",
       "           14,   34,   18,    2],\n",
       "        [   1,   42,   14,   18,   42,   66,   42,   15,   42,   42,   42,   42,\n",
       "           16,   42,   14,   15,   11,   34,   16,   35,    7,   23,   34,    8,\n",
       "            7,   34,    8,   34,   11,   27,   17,   27,   18,   11,   33,   17,\n",
       "            7,   27,    8,   27,    2, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100],\n",
       "        [   1,   33,   14,   18,   27,   27,   33,   20,   27,   27,   14,   11,\n",
       "           42,   14,   21,   42,   42,   42,   15,   42,    7,   42,   14,    8,\n",
       "           34,   27,    7,   28,    8,    7,   28,    8,   34,   15,   11,   27,\n",
       "           19,   18,   23,   34,   11,   42,   14,   22,   42,   47,   42,   42,\n",
       "           42,   14,   61,   11,   27,   20,   21,   11,   33,   19,   22,    2,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100],\n",
       "        [   1,   42,   14,   42,   42,   42,   42,    7,   27,   23,   20,   61,\n",
       "            8,   42,   14,   11,   27,    7,   34,    8,    7,   27,   27,    7,\n",
       "           23,   34,    8,   34,    8,    7,   27,   27,    7,   23,   34,    8,\n",
       "           34,    8,   27,    7,   23,   34,    8,   34,   11,   33,   18,   21,\n",
       "           19,   11,   27,   21,   27,   11,   27,   17,   27,   18,   11,   34,\n",
       "           17,   16,   11,   27,   19,   27,   11,   27,   23,   20,    7,   42,\n",
       "           14,   42,   42,   42,   42,   42,   14,    8,   42,   14,   42,   42,\n",
       "           42,   16,   42,   42,   14,    2, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100]]), 'mc_labels': tensor([[5.9534e+02, 8.0645e-01, 1.1000e+01, 1.0000e+00, 5.0000e+00, 4.2000e+01,\n",
       "         1.1000e+01, 2.0000e+01, 1.0654e+02],\n",
       "        [2.8409e+02, 3.3333e-01, 6.0000e+00, 3.0000e+00, 2.0000e+00, 1.9000e+01,\n",
       "         7.0000e+00, 5.0000e+00, 8.5790e+01],\n",
       "        [4.1010e+02, 3.3333e-01, 7.0000e+00, 1.0000e+00, 4.0000e+00, 2.8000e+01,\n",
       "         1.0000e+01, 3.0000e+00, 6.6930e+01],\n",
       "        [5.9721e+02, 2.8125e-01, 9.0000e+00, 4.0000e+00, 3.0000e+00, 4.2000e+01,\n",
       "         1.0000e+01, 1.4000e+01, 1.4460e+02]])}"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
