{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import safe as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9e60a8a2444fae95965bf0ad90c4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/alxfgh--ChEMBL_Drug_Instruction_Tuning to /home/emmanuel/.cache/huggingface/datasets/alxfgh___csv/alxfgh--ChEMBL_Drug_Instruction_Tuning-6e653d1656fb1fb2/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7a356767a34c0c9f8fb9a053403bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792fe7458cce44999c677ae6304cab6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f304240c2c4d37848163694be56a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46de948e1dc54db8a2a6de55fb826478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/emmanuel/.cache/huggingface/datasets/alxfgh___csv/alxfgh--ChEMBL_Drug_Instruction_Tuning-6e653d1656fb1fb2/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f651cf4f3f4246b038c35057d52a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset(\"alxfgh/ChEMBL_Drug_Instruction_Tuning\", streaming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = data[\"train\"]\n",
    "data = data.unique(\"SMILES\")\n",
    "df = pd.DataFrame({\"smiles\":data})\n",
    "data = datasets.Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datamol as dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "ALLOWED_DESCRIPTORS = [\"mw\", \"fsp3\", \"n_lipinski_hba\", \"n_lipinski_hbd\", \"n_rings\", \"n_heavy_atoms\", \"n_hetero_atoms\", \"n_rotatable_bonds\", \"tpsa\"]\n",
    "def apply_converter(row):\n",
    "    row[\"inputs\"] = sf.utils.convert_to_safe(row[\"smiles\"], canonical=False, randomize=True, fraction_hs=0.4)\n",
    "    descriptors_dict = dm.descriptors.compute_many_descriptors(dm.to_mol(row[\"smiles\"]))\n",
    "    row[\"descriptors\"] = [descriptors_dict[x] for x in ALLOWED_DESCRIPTORS]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e59af41cd794a32ac1aa176562e1d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3892 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:26:47] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:26:47] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:26:47] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:26:47] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:26:47] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:26:47] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:26:47] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:26:47] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "processed_data = data.map(apply_converter, batched=False, remove_columns=[\"smiles\"], num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6a6ec11c4841549f5171441c98fd53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3892 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_data = processed_data.filter(lambda x: x[\"inputs\"] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf tmp_data/processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "processed_data = processed_data.train_test_split(\n",
    "    test_size=0.2,  seed=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data[\"validation\"] = processed_data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665efd2b70734146bfbff18913c67b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b24968ef87c47acb7797aa394d36cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/751 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11f6d71a07249f6bb40fed96381d489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/751 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_data.save_to_disk(\"tmp_data/proc_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn an initial tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from safe.tokenizer import SAFETokenizer\n",
    "from safe.trainer.data_utils import batch_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = datasets.load_from_disk(\"tmp_data/proc_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322e24f0f5ae47d982acb7f5aeaad9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca42d2d2a9734e64aed1ea7ffb4f76a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641e9168c82544d59a19dc306b222034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SAFETokenizer(trainer_args=dict(vocab_size=500), splitter=None)\n",
    "tokenizer.train_from_iterator(batch_iterator(processed_data, column=\"inputs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"tmp_data/tokenizer-no-splitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['inputs', 'descriptors'],\n",
       "        num_rows: 3001\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['inputs', 'descriptors'],\n",
       "        num_rows: 751\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['inputs', 'descriptors'],\n",
       "        num_rows: 751\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_tokenizer = tokenizer.get_pretrained()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize a version of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safe.trainer.data_utils import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91247dbfd7c846f7ad496cfd99138488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d0e34695a24cad82a08fc892e912c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/751 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea9c94f945740d09692d3d8c6b3c2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/751 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = get_dataset(\"tmp_data/proc_data\", tokenizer=tokenizer, streaming=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the appropriate data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safe.trainer.collator import SAFECollator\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "data_collator = SAFECollator(tokenizer=tokenizer)\n",
    "dataloader = DataLoader(tokenized_dataset[\"train\"], collate_fn=data_collator, batch_size=4)\n",
    "for batch in dataloader:\n",
    "    break\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the training framework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (0.15.7)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from wandb) (3.1.32)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from wandb) (1.28.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from wandb) (68.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from wandb) (4.21.12)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/manu/.miniconda/envs/safe-space/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (3.0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaclandrol\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import safe\n",
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    set_seed,\n",
    ")\n",
    "from loguru import logger\n",
    "from safe.trainer.model import SAFEDoubleHeadsModel\n",
    "from safe.tokenizer import SAFETokenizer\n",
    "from safe.trainer.data_utils import get_dataset\n",
    "from safe.trainer.collator import SAFECollator\n",
    "from safe.trainer.trainer_utils import SAFETrainer\n",
    "CURRENT_DIR = os.path.join(safe.__path__[0], \"trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_LOG_MODEL=end\n",
      "env: WANDB_WATCH=all\n",
      "env: WANDB_PROJECT=safe-project\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_LOG_MODEL=end\n",
    "%env WANDB_WATCH=all\n",
    "%env WANDB_PROJECT=safe-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "config = None\n",
    "tokenizer_path = \"tmp_data/tokenizer-splitter\"\n",
    "dataset_path = \"tmp_data/proc_data\"\n",
    "model_path = None\n",
    "is_tokenized=False\n",
    "prop_loss_coeff =  1\n",
    "dtype = \"auto\"\n",
    "ddp = False\n",
    "gradient_accumulation_steps = 1\n",
    "wandb_watch = None\n",
    "wandb_run_name = f\"safe-model-{uuid.uuid4().hex[:8]}\"\n",
    "batch_size = 32\n",
    "warmup_steps = 10\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-5\n",
    "\n",
    "num_labels = 9\n",
    "logging_steps = 1\n",
    "output_dir = \"tmp_data/training/\"\n",
    "num_workers = 4\n",
    "max_steps = 10\n",
    "cache_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/manu/Code/safe/expts/notebook/tmp_data/proc_data/train/cache-a924afbc58f161eb.arrow\n",
      "Loading cached processed dataset at /Users/manu/Code/safe/expts/notebook/tmp_data/proc_data/test/cache-6a6761b8806d6d7e.arrow\n",
      "Loading cached processed dataset at /Users/manu/Code/safe/expts/notebook/tmp_data/proc_data/validation/cache-6a6761b8806d6d7e.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SAFETokenizer.load(tokenizer_path)\n",
    "training_args = transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        warmup_steps=warmup_steps,\n",
    "        num_train_epochs=num_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        logging_steps=logging_steps,\n",
    "        optim=\"adamw_torch\",\n",
    "        output_dir=output_dir,\n",
    "        report_to=\"wandb\",\n",
    "        run_name=wandb_run_name,\n",
    "        dataloader_num_workers=num_workers,\n",
    "        #save_safetensors=True,\n",
    "        #torch_compile=False,\n",
    "        max_steps=max_steps,\n",
    ")\n",
    "\n",
    "# load dataset\n",
    "with training_args.main_process_first():\n",
    "    dataset = get_dataset(\n",
    "        dataset_path, tokenizer=(None if is_tokenized else tokenizer), streaming=False\n",
    "    )\n",
    "\n",
    "data_collator = SAFECollator(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config is None:\n",
    "    config = os.path.join(CURRENT_DIR, \"configs/default_config.json\")\n",
    "config = AutoConfig.from_pretrained(config, cache_dir=cache_dir)\n",
    "setattr(config, 'num_labels', num_labels or 0 )\n",
    "\n",
    "config.vocab_size = len(tokenizer)\n",
    "config.bos_token_id = tokenizer.bos_token_id\n",
    "config.eos_token_id = tokenizer.eos_token_id\n",
    "config.pad_token_id = tokenizer.pad_token_id\n",
    "torch_dtype = dtype if dtype in [\"auto\", None] else getattr(torch, dtype)\n",
    "\n",
    "if model_path is not None:\n",
    "    model = SAFEDoubleHeadsModel.from_pretrained(\n",
    "        model_path,\n",
    "        config=config,\n",
    "        cache_dir=cache_dir,\n",
    "        torch_dtype=torch_dtype,\n",
    "        low_cpu_mem_usage=True,\n",
    "    )\n",
    "else:\n",
    "    model = SAFEDoubleHeadsModel(config)\n",
    "\n",
    "# We resize the embeddings only when necessary to avoid index errors. If you are creating a model from scratch\n",
    "# on a small vocab and want a smaller embedding size, remove this test.\n",
    "embedding_size = model.get_input_embeddings().weight.shape[0]\n",
    "if len(tokenizer) > embedding_size:\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "n_params = sum({p.data_ptr(): p.numel() for p in model.parameters()}.values())\n",
    "logger.info(f\"Training new model from scratch - Total size={n_params/2**20:.2f}M params\")\n",
    "\n",
    "\n",
    "trainer = SAFETrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    prop_loss_coeff=prop_loss_coeff,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▇▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▃▄▅▆▆▇██</td></tr><tr><td>train/learning_rate</td><td>▂▃▃▄▅▆▆▇█▁</td></tr><tr><td>train/loss</td><td>▂▃▃▆▂▁▂▂█▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>0.11</td></tr><tr><td>train/global_step</td><td>10</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>20946.1562</td></tr><tr><td>train/total_flos</td><td>42396433250688.0</td></tr><tr><td>train/train_loss</td><td>41157.02891</td></tr><tr><td>train/train_runtime</td><td>683.6371</td></tr><tr><td>train/train_samples_per_second</td><td>0.468</td></tr><tr><td>train/train_steps_per_second</td><td>0.015</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">safe-model-4f2c7cc3</strong> at: <a href='https://wandb.ai/maclandrol/safe-project/runs/n9csbtov' target=\"_blank\">https://wandb.ai/maclandrol/safe-project/runs/n9csbtov</a><br/>Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230725_234341-n9csbtov/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# safe-train --tokenizer  \"tmp_data/tokenizer-splitter\" \\\n",
    "#     --dataset \"tmp_data/proc_data\" \\\n",
    "#     --num_labels 9 \\\n",
    "#     --torch_compile False \\\n",
    "#     --optim \"adamw_torch\" \\\n",
    "#     --learning_rate 1e-5 \\\n",
    "#     --prop_loss_coeff 1e-3 \\\n",
    "#     --gradient_accumulation_steps 1 \\\n",
    "#     --is_tokenized False \\\n",
    "#     --output_dir \"tmp_data/test/\" \\\n",
    "#     --wandb_project \"safe-project\" \\\n",
    "#     --max_steps 5\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
